1. Basics of Containerization
	◦ Introduction to Containerization
---------------------------------------------------------------------------------------------------------------------------	
	Point wise Introduction to Containerization

Definition of Containerization:

	Containerization 
		lightweight, 
		portable, and 
		efficient method of 
			packaging, distributing, and executing software applications.

Isolation of Applications:
	Containers encapsulate applications along with their dependencies, ensuring they run consistently across various environments without conflicts.

Components of a Container:
	A container encapsulate 
		applications 
		their dependencies the application code
		runtime, 
		libraries, and 
		system tools, all packaged together as a single unit.
---------------------------------------------------------------------------------------------------------------------------	
	◦ Benefits of Containers
---------------------------------------------------------------------------------------------------------------------------	
	


Portability: 
	Containers can run consistently across different environments, from development to production.
Resource Efficiency: 
	Containers share the host OS kernel, making them lightweight and quick to start compared to virtual machines.
Scalability: 
	Containers can scale easily, allowing applications to handle varying workloads.

Containers use 
	namespaces and cgroups 
		to create isolated environments, ensuring applications do not interfere with each other.

Microservices Architecture:
	Containerization aligns well with microservices architecture, allowing developers to build and deploy applications as a collection of loosely coupled services.

Docker as a Popular Containerization Platform:
	Docker is a widely used containerization platform that simplifies the creation and management of containers, making them accessible to developers.

DevOps and Continuous Integration/Continuous Deployment (CI/CD):


Containerization has 
	vibrant ecosystem 
	variety of 
		tools, 
		registries, and 
		platforms
	dynamic and evolving technology in the field of software development and deployment.


Resource Efficiency:
	Containers share the host operating system's kernel, resulting in lower overhead compared to virtual machines, leading to quicker startup times and efficient use of system resources.

Isolation:
	Containers provide a level of isolation
		using features like namespaces and cgroups
		ensuring that each container runs independently without interfering with others on the same host.

Scalability:
	Containers can be easily scaled out/in or up/down to handle varying workloads, providing flexibility and responsiveness to changes in demand.

Consistency:
	Containers package the application and its dependencies in a standardized manner, reducing the "it works on my machine" problem and ensuring consistent behavior across different environments.

Microservices Architecture:
	Containers align well with microservices architecture, allowing developers to build and deploy applications as modular and loosely coupled services.

DevOps and CI/CD Integration:

Containers support continuous integration and continuous deployment (CI/CD) practices, enabling automated testing, integration, and deployment of applications throughout their lifecycle.
Versioning and Rollback:
	Containers facilitate versioning of applications, making it easier to roll back to previous versions in case of issues, and ensuring a smoother deployment process.

Ecosystem and Orchestration:
	Containers have a rich ecosystem of tools and platforms, with popular orchestration tools like Kubernetes providing automation, scaling, and management capabilities for containerized applications.

Development Speed:
	Containers enable faster development cycles by allowing developers to work in consistent environments, reducing the time spent on configuring and troubleshooting differences between development and production setups.	

Container Orchestration:
	Tools like Kubernetes and Docker Swarm manage the deployment, scaling, and operation of containerized applications, providing automation and coordination.


	
---------------------------------------------------------------------------------------------------------------------------
	◦ Comparison with Virtualization
---------------------------------------------------------------------------------------------------------------------------	
	
Containers 
-----------
	Isolation Mechanism:

	Lightweight Isolation: 
		Containers share the host OS kernel and utilize features like namespaces, providing lightweight isolation, making them faster to start and more resource-efficient.

	Resource Overhead:
		Low Overhead: 
			Containers have minimal overhead since they share the host OS, resulting in quicker deployment and more efficient resource utilization.

	Portability:
		High Portability: 
			Containers encapsulate the application and its dependencies, ensuring consistent behavior across different environments, making them highly portable.
	Scaling:
		Efficient Scaling: Containers can be quickly scaled up or down to handle varying workloads, offering flexibility and responsiveness to changes in demand.

	Ecosystem:
		Dynamic Ecosystem: Containers have a dynamic ecosystem with tools like Docker and Kubernetes, providing extensive support for development, deployment, and orchestration.


Virtualization:
---------------
	Isolation Mechanism:

	Heavyweight Isolation: 
		Virtual machines (VMs) provide stronger isolation by emulating an entire operating system, resulting in higher resource overhead and slower startup times.
	Resource Overhead:
		Higher Overhead: 
			VMs require a hypervisor and a separate guest OS for each instance, leading to higher resource overhead and longer boot times.

	Portability:
		Less Portable: 
			VMs are less portable than containers as they encapsulate the entire operating system, making them heavier and more dependent on specific virtualization platforms.
	Scaling:
		Scaling Challenges: 
			While VMs can be scaled horizontally, the process is typically slower and involves more significant resource allocation compared to containers.
	Ecosystem:
		Mature Ecosystem: Virtualization has a mature ecosystem with hypervisors like VMware and virtualization management tools, but it may not be as dynamic as the container ecosystem.
	Common Considerations:
		Use Case: Containers are often preferred for microservices architecture, lightweight applications, and cloud-native development. Virtualization is more suitable for running multiple diverse workloads on a single physical server.

	Resource Utilization: 
		Containers are more resource-efficient due to their lightweight nature, making them ideal for environments where resource optimization is critical.

	Isolation Needs: 
		If strong isolation is required between applications or workloads, virtualization may be a better choice. Containers provide a balance between isolation and resource efficiency.

	Startup Time: 
		Containers have faster startup times, making them suitable for dynamic and rapidly changing environments. VMs typically have longer boot times.





Quick walk through of 
	Namespaces
	CGroups
	COW
	
---------------------------------------------------------------------------------------------------------------------------	
lab:
	Create a virtual machine using vagrant and oracle virtual box.
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
	Create a docker container of the same.
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------
Hands on deep dive into the difference

2. Best Practices to Write a Docker from Scratch
---------------------------------------------------------------------------------------------------------------------------	
	
a. Start with a Minimal Base Image:
	Begin with a minimal base image 
		reduce the attack surface 
		Better performance. 
	Popular choices include Alpine Linux or official language runtimes' slim variants.


FROM alpine:latest


b. Update and Upgrade Packages:
	Ensure that system packages are up-to-date within the base image to address security vulnerabilities.
RUN apk update && apk upgrade

	Be careful to do apk upgrade though 
	-----------------------------------
		Unpredictable Updates: 
			can update any package in the repository
			introduce incompatibilities in application 
		Cache Invalidation: 
			apt upgrade 
				one layer invalidates the previous layer
				Can lead to larger image sizes and slower builds.
		Security Concerns: 
			could potentially introduce security vulnerabilities 
				needs thorough testing 
				
	Recommendation: Create a base image with necessary updates and get it blessed by security.
	

c. Install Only Necessary Dependencies:
	Install only the dependencies required for your application 
		to minimize the image size and potential security risks.

	RUN apk add --no-cache <package1> <package2>
--------------------------------------
apk command is used for package manager for alpine.

what --no-cache does?

Package Index Update:

By default, apk add uses a local package index cache to quickly locate and install packages. This cache is created when the package index is updated using apk update. If the cache is not present or is outdated, the --no-cache option ensures that the package index is updated before installing packages.
Avoiding Cache in Package Installation:

When installing packages without --no-cache, the package manager may use the cached packages from the local cache if they are available and up-to-date. This can speed up the installation process, but it may lead to using outdated packages or encountering issues if the local cache is stale.
Fresh Installation:

The --no-cache option ensures that the package installation is performed as a fresh download from the repositories, bypassing any local cache. This guarantees that the latest version of the packages is fetched and installed.
--------------------------------------


d. Use COPY Wisely:
	Copy only necessary files into the image to avoid unnecessary bloat. 
	Use a .dockerignore file to exclude irrelevant files.

	COPY . /app

e. Specify the Working Directory:
	Set the working directory to avoid path-related issues and improve clarity in your Dockerfile.


	WORKDIR /app

f. Reduce Layers with Multi-stage Builds:
	Use multi-stage builds 
		minimize the number of layers 
		create a smaller final image for production.


	FROM builder as build
	# Build stage

	FROM alpine:latest
	COPY --from=build /app /app
	# Final stage


g. Clean Up After Each Step:

	Remove unnecessary artifacts.

	RUN apk del <package> && rm -rf /var/cache/apk/*





h. Run as Non-Root User:

	For security reasons, run your application as a non-root user. Create a user and switch to it.

	RUN adduser -D myuser
	USER myuser
	
	Refer: D:\PraiseTheLord\HSBGInfotech\Others\vilas\docker-k8s\dockerfiles\UserDockerfile.txt

i. Expose Only Necessary Ports:

	Only expose the ports that your application needs, and consider using dynamic port assignment.

	EXPOSE 8080

j. Document Your 

	Include comments and labels in your Dockerfile to provide clear documentation about its purpose, how to use it, and any other relevant information.

	# Description: My custom Dockerfile for an application
	# Usage: docker build -t my-app .	

-----------------------------------------------------------------

	- One common remove Vs remove at each stage.
	--------------------------------------------
	

FROM base-image

# Stage 1: Install dependencies and build application
RUN apt-get update \
    && apt-get install -y dependencies \
    && build-something \
    && cleanup \
################################ 	
#### Remote at each stage 	
################################
    && rm -rf /var/lib/apt/lists/*

# Stage 2: Add application code
COPY . /app

################################
####  Stage 3: Final cleanup
################################
RUN cleanup \
    && rm -rf /tmp/*
	
	
	
Layering:
	One Common Remove/Cleanup Step: 
		Fewer layers if RUN is the command to be cleaned.
	Remove at Each Stage: 
		More layers, as each stage has its own cleanup step.

Intermediate Image Size:

One Common Remove/Cleanup Step: The intermediate image size is smaller because the cleanup is performed within the same layer.
Remove at Each Stage: Each stage's intermediate image may be larger, but the final image size is optimized.
Build Cache:

One Common Remove/Cleanup Step: Changes in any step invalidate the entire cache from that point forward.
Remove at Each Stage: Each stage is cached individually, improving build speed when changes occur in later stages.
Readability and Maintainability:

One Common Remove/Cleanup Step: Simpler Dockerfile with fewer instructions, but cleanup steps might be distant from the operations they relate to.
Remove at Each Stage: More granular control and better separation of concerns, but Dockerfile can be longer.		
	
---------------------------------------------------------------------------------------------------------------------------
	◦ Starting with a Base Image
---------------------------------------------------------------------------------------------------------------------------	
	

Selecting the right base image is a crucial step in creating an efficient and secure Docker container. Here are steps to help you identify the right base image:

Why slim or alpine containers 
	smaller base image
	smaller surface area of attack 
	better performance.


a. Understand Application Requirements:
	Identify the specific requirements of your application
		e.g. 
			runtime dependencies
				e.g. in java .m2/.m3 directories.
			libraries, and 
			tools it needs.
			kind of upgrade that may be required etc.
			
		For e.g. in maven /home/user/.m2 access is required.	
			
b) Consider Security and Size:
	Prioritize base images which are 
		- security-hardened and 
		- has minimal size. 
			reduce attack surfaces 
			faster 
				download and 
				deployment times.
c) Official Images:
	Prefer using official images 
		provided by the maintainers of the underlying technology 
			(e.g., language runtime, database). 
		These images are usually 
			well-maintained, 
			regularly updated, and 
			more secure.
e.g.
	c. FROM node:14-alpine

	Check Image's Maintenance Status:
		Evaluate the maintenance status of the base image. 
		Choose images that are 
			actively maintained and 
			receive timely security updates.

		Alpine Linux for Minimalism:
			Consider using Alpine Linux as a base image. 
			Advantage 
				minimal size 
				security-focused design
				networking support 
				better performance.

	c. FROM alpine:latest

		Official Language Runtimes:
			When working with specific programming languages, 
				use official language runtime images 
					pre-configured and 
					optimized for that language.

D. FROM python:3.9-alpine

	Check for Common Use Cases:
		Look for base images tailored to common use cases
			e.g. 
				development, 
					jdk
				production
					jre
				CI/CD
			These images might include additional tools specific to those scenarios.

FROM node:14-alpine as development

	Review Community Images:
		Explore community-maintained images on Docker Hub. 
		Check for images with good documentation, usage examples, and positive community feedback.

	FROM nginx:latest

	Scrutinize Layers and Components:
		Inspect the layers and components included in the base image. Ensure it only includes necessary components to minimize the attack surface.

	Regularly Update Base Images:
		Regardless of the base image chosen, make it a practice to regularly update your Dockerfile with the latest version of the base image to benefit from security updates and improvements.


	FROM node:14-alpine

	By following these steps, you can make informed decisions about the base image, balancing factors such as security, size, and compatibility with your application's requirements. Regularly review and update your base image to stay current with the latest improvements and security patches.	
		
		
Search for Python in hub.docker.com 
	Official/
	
	
	e.g. Common tags in images 
	---------------------
	Slim images: 
		smaller images 
		exclude unnecessary components
		suitable for production 
		use when a minimal image size is crucial.

	Debian images (Bookworm, Bullseye): 
		Debian is a widely used Linux distribution known for its stability. The different codenames represent different major releases.

	Alpine images: 
		Alpine Linux is known for its small size and security features. 
		It is often favored for lightweight and minimal containers.
			
---------------------------------------------------------------------------------------------------------------------------	
	Hands on: considerations for identifying a base image.
---------------------------------------------------------------------------------------------------------------------------	
	
	Students to use their preferred image and identify.
	
	
	e.g. 1 tomcat application in normal way 



	e.g. 2 node application in normal way 	
	
	
Developing a web application using Node.js
	choose the right base image for your Docker container. 
	different options for base images and identify the most suitable one based on various considerations.

Use Case: Developing a Node.js Web Application

Options for Base Images:

a. Official Node.js Image:

Description: Official Node.js images are provided by the Node.js maintainers, optimized for running Node.js applications.

FROM node:14
WORKDIR /app
COPY package.json .
RUN npm install
COPY . .
CMD ["npm", "start"]



b. Considerations:
	Well-maintained and regularly updated.
	Includes essential tools for Node.js development.
	Good choice for development and production.

c. Alpine Linux Image:

Description: Alpine Linux is known for its minimal size and security features. Using the Alpine variant of the Node.js image can result in a smaller container size.

dockerfile

FROM node:14-alpine
WORKDIR /app
COPY package.json .
RUN npm install
COPY . .
CMD ["npm", "start"]

Considerations:
	Smaller image size compared to non-Alpine variants.
	Suitable for production where minimizing image size is crucial.
	Customized Image with Development Tools:

Description: For a development environment, you might need additional tools like debuggers or code editors. You can start with an official Node.js image and customize it accordingly.


FROM node:14
WORKDIR /app
RUN npm install -g nodemon
COPY package.json .
RUN npm install
COPY . .
CMD ["nodemon", "app.js"]

Considerations:
	Ideal for a development environment.
	Additional tools installed for ease of development and debugging.
	Steps to Choose the Right Base Image:

Identify Application Requirements:
	Understand the specific requirements of your Node.js application
	considering factors like 
		development/production, 
		size constraints
		necessary tools.
Consider Security and Size:
	If minimizing image size is crucial
		consider Alpine variant for production. 
	For development
		additional tools over a slightly larger image size.
Evaluate Maintenance Status:
	Check the maintenance status of 
		official Node.js images and 
		Alpine variants. 
	Choose a base image that is actively maintained and receives timely updates.
Review Use Case Considerations:
	For production-ready application
		official Node.js image or 
		Alpine variant 
			may be suitable. 
	For a development environment
		customizing the image with additional tools.
Test and Iterate:
	Build and test your Docker image with different base image options. Evaluate factors such as build time, container startup time, and overall performance.
Document Your Decision:
	Clearly document the choice of the base image in your Dockerfile, along with any specific considerations and reasons for choosing a particular variant.
By going through these steps, you can make an informed decision on the right base image for your Node.js web application, balancing factors such as security, size, and development requirements. Regularly review and update your Dockerfile to stay aligned with best practices and any changes in your application's dependencies.





	
---------------------------------------------------------------------------------------------------------------------------	
		Options
	---------------------------------------------------------------------------------------------------------------------------	
	already covered.
	
	
	
	
---------------------------------------------------------------------------------------------------------------------------	
		Thought process
---------------------------------------------------------------------------------------------------------------------------	
	
	

1. Understand the Purpose:

	What application are you containerizing? 
	What are its dependencies?
	What is the intended environment? 
		Development, testing, or production?

2. Prioritize Efficiency and Security:

	Minimize the base image size: 
		Use official, well-maintained base images like 
			tomcat:latest or slim variants like openjdk:17-slim.
			Is latest good?
	Multi-stage builds: 
		Separate 
			build and 
			runtime stages .
	Minimize install steps: 
		Only install essential dependencies required for your application to run.
	User context: 
		Avoid running commands as root inside the container. 
		Instead, use non-root users.

3. Reproducibility and Maintainability:

	Document all steps clearly: 
		Make it easy to understand the purpose of each line.
	Use environment variables: 
		Store configuration values as environment variables 
			for easier management and updates.
	Version control: 
		Include the Dockerfile in your version control system for tracking changes.

4. Optimization for Deployment:

	Expose only necessary ports: 
		Restrict access to ports.
	Consider volume mounts: 
		Mount persistent data volumes for configurations or application data 
			outside the container.
		VOLUME attaches to a annonymous volume.
	Entrypoint and command: 
		Define clear entry points and commands for starting your application within the container.

5. Contextualize and Adapt:

	Adapt and customize the Dockerfile 
		based on 
			specific application's needs 
			target environment.
	Security best practices: 
		Research and implement additional security measures relevant to your application and deployment environment.
		
---------------------------------------------------------------------------------------------------------------------------		
Best practices
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------
	◦ Minimizing Layers and Image Size
---------------------------------------------------------------------------------------------------------------------------	
	Why minimize layers of images?
	
	

1. Minimize the number of layers:

	Combine RUN statement: 
		This reduces the number of intermediate layers created during the build process. For example, instead of separate commands for installing each dependency, combine them into one RUN statement with multiple apt-get install or apk add commands.
	Use multi-stage builds: 
		Split your Dockerfile into two stages. The first stage can be used to install dependencies and copy application files. The second stage can use a smaller base image and copy only the necessary files from the first stage. This eliminates unnecessary layers from the final image.

	Commands can be combined in many commands like :
		RUN 
		CMD
		Entrypoint
		COPY/ADD 
			COPY file1.txt file2.txt /destination/
		EXPOSE 	
		ENV
			ENV VAR1=value1 \
				VAR2=value2 \
				VAR3=value3


2. Use smaller base images:

	Choose minimal base images: 
		Opt for base images like Alpine Linux or BusyBox instead of full-fledged distributions like Ubuntu or Debian. These minimal images are significantly smaller and have fewer dependencies.
	Use slim variants: 
		Many official base images offer "slim" variants that come pre-configured with a minimal set of packages. For example, use openjdk:17-slim instead of openjdk:17.

3. Remove unnecessary files and dependencies:

	Use .dockerignore file: 
		This file specifies files and directories to be excluded from the build context. Excluding unnecessary build artifacts, temporary files, and documentation significantly reduces the image size.
	Clean up after installations: 
		Use commands like apt-get autoremove or apk del to remove automatically installed dependencies that are no longer needed.
	Install only essential dependencies: 
		Analyze your application's requirements and install only the specific packages required for its functionality. Avoid installing unnecessary packages or pre-built libraries that your application doesn't use.

4. Utilize other optimization techniques:

	Compress static assets: 
		If your application includes static assets like images or JavaScript files, consider compressing them before adding them to the image. This can significantly reduce their size without impacting functionality.
	Leverage caching: 
		Docker uses a layer caching mechanism. Reusing cached layers during subsequent builds can significantly speed up the build process, especially for multi-stage builds.
	Explore Docker image optimization tools: 
		Tools like docker-slim can analyze and optimize Docker images, helping you identify and remove unnecessary layers and further reduce the image size.
	
---------------------------------------------------------------------------------------------------------------------------
		Hands on:
---------------------------------------------------------------------------------------------------------------------------	
	My tomcat Dockerfile - what are the different ways to minimize layers?
---------------------------------------------------------------------------------------------------------------------------		
			Multi-stage build
---------------------------------------------------------------------------------------------------------------------------	
	
		Refer multi-stage folder 
			DockerfileExample.txt
			PythonDockerfile.txt
	
---------------------------------------------------------------------------------------------------------------------------		
		Understanding the relevance and real value of the same.
	---------------------------------------------------------------------------------------------------------------------------	
		Slimmer version
		Better performance 
		Better security
---------------------------------------------------------------------------------------------------------------------------
	◦ Efficient Use of Dockerfile Instructions
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		Hands on:
		Deep dive into various instructions and best practices.
---------------------------------------------------------------------------------------------------------------------------	
	My examples 
	
	
---------------------------------------------------------------------------------------------------------------------------		
	◦ Properly Setting Environment Variables
---------------------------------------------------------------------------------------------------------------------------	
	
	
Setting environment variables effectively is crucial for managing configurations and secrets within your Docker containers. Here are several methods you can use:

1. Using the -e flag with docker run:

	This method allows you to set environment variables directly when running a container:
	
	docker run -e ENVIRONMENT_VARIABLE=value my-image

	Advantages
		simple and convenient for 1 or 2 values
	Disadvantages		
		cumbersome for managing multiple variables 
		isn't ideal for sensitive information 
			but still used 
	
2. Setting environment variables in the Dockerfile:

Use ENV instruction in Dockerfile:

ENV ENVIRONMENT_VARIABLE=value

	This approach encapsulates environment variable definitions within the image itself, promoting consistency and reusability.
	It also improves security by not exposing the values in the command history.
	However, updating these values requires rebuilding the image, which can be time-consuming.

3. Using a .env file:

Create a .env file in your project directory containing environment variable definitions:

---------------------------
ENVIRONMENT_VARIABLE=value
another_variable=other_value
---------------------------

Use the --env-file flag with docker run to reference the .env file:

docker run --env-file=.env my-image


This approach separates environment variables from your Dockerfile, simplifying management and allowing you to keep sensitive information out of your version control system.
However, it requires passing the .env file during each container run, which can be cumbersome for complex deployments.

4. Using Docker Compose environment variables:

If you use Docker Compose, you can define environment variables within the environment section of your docker-compose.yml file:

services:
  my-service:
    environment:
      ENVIRONMENT_VARIABLE: value
      another_variable: other_value
Use code with caution.
This approach offers centralized management of environment variables for your entire application stack defined in the Compose file.
It also provides environment variable precedence, where variables defined in the Compose file override those set through other methods.
Choosing the right approach depends on your specific needs:

For simple deployments or testing, the -e flag might suffice.
For production environments and sensitive information, using a .env file or Docker Compose environment variables is recommended for security and maintainability.
Remember to avoid storing sensitive information (passwords, API keys) directly in your Dockerfile or .env file. Consider using dedicated secrets management solutions for secure storage and retrieval in production environments.
	
---------------------------------------------------------------------------------------------------------------------------	
		Ideal scenarios to consider using env
---------------------------------------------------------------------------------------------------------------------------	
	Various ways to load env from a file 
	------------------------------------
		https://stackoverflow.com/questions/46917831/how-to-load-several-environment-variables-without-cluttering-the-dockerfile
	
	
	
1. Configuration Management:

	Separating configuration from code: 
		decouple configuration 
			e.g. 
				database connection strings
				API endpoints
				logging levels from your application code. 
		
		keeps your code clean 
		reusable across different environments.
	Environment-specific configurations: 
		Can define different environment variables for 
			development, 
			testing, and 
			production 
				using .env files
		enabling flexible configuration management based on the deployment context.

2. Non-Sensitive Application Settings:

	Configurable parameters: 
		Use environment variables for settings 
			can be adjusted at runtime 
			e.g. 
				enabling/disabling features
					e.g. Feature flagging
				setting logging verbosity
				specifying cache sizes. 
			
3. Managing Secrets (Limited Use Case):

	Not ideal for highly sensitive information, 
		Environment variables can be used for secrets like 
			API keys 
			short-lived tokens. 
		Advice:
			Don't use ENV for 
				extremely sensitive data like 
					passwords or 
					encryption keys in your Dockerfile or 
					.env files. 
				Use dedicated secrets management solutions 

4. Integration with External Services:

	Environment variables 
		applications 
			connect to external services. 
	e.g.
		API endpoints
		authentication credentials, or 
		service URLs. 
	Advantage
		simplifies configuration 
		easy integration with 
			different external services.
5. Simplifying Deployment Management:

	streamline deployment processes 
		don't modify application code 
		configuration files 
			specific to each deployment environment. 
		
Remember: When using environment variables, consider the following best practices:
	Security: 
		Don't store highly sensitive information in environment variables
			especially within your Dockerfile or .env file.
	Readability: 
		Use clear and descriptive names for your environment variables.
	Documentation: 
		Document the usage and purpose 
	
---------------------------------------------------------------------------------------------------------------------------		
		What are the different options.
			What are the alternatives

---------------------------------------------------------------------------------------------------------------------------	
	
Alternative options to consider depending on your specific needs and security concerns:

1. Multi-stage builds:

	separate build and runtime environments 
	This allows you to:
		Install dependencies of application in separate stage.
		Copy only the necessary files and configuration 
			(e.g., configuration files) to the final image.
		Avoid including environment variables with sensitive information 
			in the final image, enhancing security.
2. Argument passing:

	Pass arguments directly 
		in docker run command 
			along with the --entrypoint flag:
	
		e.g. 
			docker run --entrypoint ["my-app", "-c", "production"] my-image
	Can pass configuration values as arguments 
		to your application's entry point script
		keeping them outside the container image.
	Disadvantages	
		arguments are visible in the command history
		limiting their suitability for sensitive information.
3. Configuration files:

	Use volumes 
		Store configuration in a files like 
			JSON, YAML, or INI files 
		mount them as volumes into your container. 
		
	Advantage
		Dynamic updates to the configuration files 
			without rebuilding the image.
		Improved security 
			keep sensitive information outside the container image.
		
4. Secret management tools:

	For highly sensitive data like 
		use dedicated secret management tools like 
			e.g. 
				HashiCorp Vault
				AWS Secrets Manager
				Azure Key Vault. 
	These tools:
		Securely store and manage secrets outside the container image.
		Provide 
			controlled access and 
			authorization to secrets 
				through secure mechanisms.
		Inject secrets into your application at runtime 

Choosing the best alternative depends on several factors:

	Sensitivity of the data: 
		For highly sensitive data, prioritize dedicated secret management solutions.
	Deployment complexity: 
		If frequent configuration updates are required, consider options like argument passing or configuration files.
	Security requirements: 
		Multi-stage builds and secret management tools offer better security practices for production environments.


---------------------------------------------------------------------------------------------------------------------------		
	◦ Cleaning Up Unnecessary Files
---------------------------------------------------------------------------------------------------------------------------	
	
	1. Multi-stage Builds:

		This is the recommended approach for efficient image size reduction and improved security.
		It involves creating multiple stages in your Dockerfile:
		Stage 1 (Build): Includes the base image, installs dependencies, and builds your application.
		Stage 2 (Final): Uses a minimal base image and copies only the essential files from the build stage (e.g., compiled code, configuration files) and application dependencies truly needed for runtime.
		This approach offers several benefits:
		Reduced image size: Only necessary files are included in the final image.
		Improved security: Excludes unnecessary build tools and libraries, reducing the attack surface.
		Enhanced caching: Docker can reuse cached layers from the build stage for subsequent builds, improving efficiency.
	2. Using the RUN Instruction:

		You can use the RUN instruction with commands like rm or find to explicitly remove unwanted files during the build process.
		Advantages:
		Simpler implementation: No need for complex multi-stage builds.
		Granular control: Allows for removing specific files or directories.
		Disadvantages:
		Error-prone: Incorrect usage of rm can lead to unintended consequences and missing files.
		Non-reusable: Requires repeating the cleanup process in every build stage if needed.
		Less efficient: Doesn't leverage image layer caching as effectively as multi-stage builds.
	3. Utilizing .dockerignore file:

		Create a .dockerignore file in your project directory. This file specifies file patterns or directories to be excluded from the build context.
		This helps prevent unnecessary files like:
		Build artifacts
		Temporary files
		Documentation
		Development environment-specific configurations
		This approach simplifies image building by automatically excluding unwanted files from the beginning.
	4. Combining Techniques:

		For optimal results, you can often combine these techniques:
		Use the RUN instruction for specific file removals within stages.
		Leverage multi-stage builds for overall image size optimization.
		Utilize a .dockerignore file to exclude unnecessary files throughout the build process.
	Important Considerations:

		When using the RUN instruction, be cautious and test thoroughly to avoid unexpected behavior or missing files.
		Balance cleaning up files with ensuring all essential files and libraries are included for your application to function correctly.
		When handling sensitive information, ensure proper deletion techniques to prevent residual data exposure within the image layers.
	
	
	
	Different ways of cleanup using RUN command
	-------------------------------------------
	RUN rm 
	RUN apt-get remove 
	RUN apt-get clean
		my tomcat Dockerfile clean up 
	
---------------------------------------------------------------------------------------------------------------------------	
		Hands on: cleanig files.
	---------------------------------------------------------------------------------------------------------------------------	
D:\PraiseTheLord\HSBGInfotech\Others\vilas\docker-k8s\dockerfiles\CleanUpDockerfile.txt
	

---------------------------------------------------------------------------------------------------------------------------	
		dockerignore 
	---------------------------------------------------------------------------------------------------------------------------	
	
	
A .dockerignore file is a valuable tool in your Docker development workflow. 
It helps you exclude unnecessary files and directories from being included in your Docker image, resulting in a leaner and more efficient image. Here's an example .dockerignore file and an explanation of its contents:

# Ignore environment-specific configuration files
.env

# Ignore temporary build artifacts
**/target/
**/node_modules/
**/bower_components/
**/.npm/

# Ignore logs and other temporary files
**/logs/
**/tmp/
**/cache/

# Ignore test coverage reports
**/coverage/

# Ignore IDE-specific files
.idea/
.vscode/

# Ignore version control system files
.git/
.svn/
.hg/

# Ignore documentation files
**/docs/

# Ignore development scripts
**/dev-scripts/*.sh
**/dev-scripts/*.bat
Explanation:

Each line in the .dockerignore file specifies a file or directory pattern to be excluded using shell-like globbing patterns.

Lines starting with # are comments and ignored by Docker.

Common patterns include:
	*.txt: 
		Excludes all files with the .txt extension.
	**/: 
		Matches directories at any level.
	!: 
		Negates the pattern 
		(e.g., !README.md includes the README.md file).


Remember:

	Place the 
		.dockerignore file 
			in root directory of your project
		along with Dockerfile.
	Docker will automatically exclude any 
		files or 
		directories 
			matching the patterns 
	Regularly review and update your .dockerignore file 
		
	
---------------------------------------------------------------------------------------------------------------------------	
		--chown in COPY # COPY --chown=user:user source destination
---------------------------------------------------------------------------------------------------------------------------	
		
	
The COPY --chown flag
	introduced in Docker 17.09
	allows you to set the ownership of the destination directory or file to a specific user and group.

The syntax for using COPY --chown is as follows:

dockerfile

COPY --chown=<user>:<group> <source> <destination>

<user> 
	username or UID (User ID) 
		for the destination file or directory.
<group> 
	group name or GID (Group ID) 
		for the destination file or directory.
<source> 
	path to the file or directory on the host machine.
<destination> 
	path inside the Docker image where the file or directory will be copied.	


NB: This is important when you use non-root user in Dockerfile.

---------------------------------------------------------------------------------------------------------------------------	
		Cleaning files vs multi-stage build
---------------------------------------------------------------------------------------------------------------------------	

Both cleaning up files in a Dockerfile and using multi-stage builds are techniques to reduce the size of your Docker image, but they achieve this goal in different ways and have their own advantages and disadvantages. Here's a breakdown of each approach:

1. Cleaning Up Files in Dockerfile:

	Method: 
		Use RUN command 
			RUN rm -rf exact-file.
	Advantages:
		Simpler implementation
		Granular control
		Inline execution can reduce layers
			RUN mvn clean package && rm -rf target/somefile
		
	Disadvantages:
		Risk-prone: 
			you loose the file completely.
		Non-reusable: 
			Requires repeating the cleanup process in every build stage if needed.
		Less efficient: 
			Doesn't leverage image layer caching as effectively as multi-stage builds.
2. Multi-stage Builds:

	Method: 
		creates separate stages in your Dockerfile. 
		first stage 
			installing dependencies, 
			compiling code
			perform other necessary build tasks. 
		The final stage 
			copies only the essential files and configurations 
				into a minimal base image
			leaving behind all temporary files and dependencies from the first stage.
	Advantages:
		Improved image size: 
			Reduces image size by only including necessary files in the final image.
		Enhanced security: 
			Excludes unnecessary build tools and libraries from the final image, potentially reducing the attack surface.
		Better caching: 
			Docker can reuse cached layers from the first stage for subsequent builds, improving build efficiency.
	Disadvantages:
		More complex: 
			Requires more understanding of Dockerfile commands and multi-stage build concepts.
		Less granular control: 
			You cannot selectively remove specific files within the final image after the copy operation.

	Choosing the best approach:

		Simple builds: If your build process is straightforward and requires minimal file cleanup, using the RUN instruction might suffice.
		Complex builds or security concerns: For larger builds, complex dependencies, or situations where reducing the attack surface is crucial, using multi-stage builds is strongly recommended.
	Additionally:

		You can combine both approaches for optimal results. Use RUN instructions for specific file removals within stages, and utilize multi-stage builds for overall image size optimization.
		Remember to test your Dockerfile thoroughly after making changes, regardless of the method used for cleaning up files.

	
---------------------------------------------------------------------------------------------------------------------------		
	◦ Optimizing Image Caching
---------------------------------------------------------------------------------------------------------------------------	
	
	1. Leverage Layer Caching:

		Docker automatically caches layers based on the instructions used to create them.
		By optimizing your Dockerfile, you can significantly improve build performance by taking advantage of cached layers.
		Strategies for optimizing layer caching include:
			Using multi-stage builds: 
				Separate build and runtime environments to prevent unnecessary dependencies from being included in the final image, minimizing the layers that need to be rebuilt.
			Minimizing RUN instructions: 
				Combine multiple RUN instructions whenever possible to reduce the number of layers and improve cache reuse.
			Utilizing caching-friendly base images: 
				Choose base images that are frequently updated and have a high hit rate in public registries like Docker Hub.
	2. Utilize Build Caches:

		configure build caches 
			through the docker build -c flag. 
			instructs Docker to store intermediate build stages
				enabling faster subsequent builds for the same image.
		Build caches 
			good for complex builds 
			involving frequent updates to specific parts of the codebase. 
		However, be mindful of 
			their size 
			consider strategies like 
				expiring old or 
				unused entries 
					to manage their growth.
	3. Employ Content Delivery Networks (CDNs):

		For images used in your application, 
			consider utilizing a CDN 
				improve delivery speed 
				reduce load on your application servers.
		CDNs store cached copies of your images geographically distributed servers, 
			minimize latency 
			This approach is particularly beneficial for static content or images with high access frequency.
	4. Utilize Image Pruning:

		Docker allows you to remove unused image layers and containers using the docker image prune command.
		This helps reclaim disk space by eliminating unnecessary data, especially in environments with frequent image builds or experimentation.
		Consider implementing automated pruning tasks to maintain optimal storage utilization.
	5. Invest in Build Cache Management Tools:

		For complex build environments or large-scale deployments, consider utilizing dedicated build cache management tools.
		These tools offer functionalities like:
		Centralized cache management: Streamline management across multiple build machines.
		Versioning and invalidation: Control cache versions and invalidate outdated entries.
		Metrics and analytics: Gain insights into cache usage and identify optimization opportunities.
	
	
	Choosing the right approach:

	The optimal strategy for optimizing image caching depends on your specific needs and environment. Consider factors like:

		Build complexity: 
			For simple builds, basic layer caching might suffice.
		Build frequency: 
			If builds are frequent, build caches and automated pruning become more important.
		Image size and usage: 
			Utilize CDNs for frequently accessed images and consider image size optimization techniques.
		Deployment infrastructure: 
			Centralized cache management tools might be beneficial for large-scale deployments.
		By implementing these strategies and tailoring them to your specific workflow, you can achieve significant improvements in build times, reduce storage usage, and enhance the overall efficiency of your Docker image management.
---------------------------------------------------------------------------------------------------------------------------	
		Difference between default caching and docker build -c
---------------------------------------------------------------------------------------------------------------------------	

1. Default Layered Caching:

	Mechanism: Docker automatically caches layers based on the instructions used to create them. Each instruction (e.g., RUN, COPY, ADD) in your Dockerfile creates a new layer.
	Benefits:
	Automatic: No additional configuration is required.
	Reduces build time: Reuses existing layers across builds with identical instructions, eliminating the need to rebuild them.
	Improves efficiency: Minimizes resource usage and build time for subsequent builds.
	Limitations:
	Limited control: You don't have granular control over which layers are cached.
	Cache invalidation: Only the entire layer is invalidated when a change is made within it, potentially leading to unnecessary rebuilding of subsequent layers.
2. -c option with docker build:

	Mechanism: This option allows you to explicitly specify a directory to be used as a build cache. Layers from previous builds stored in this directory are reused during the current build.
	Benefits:
	More control: Provides control over the location and contents of the cache.
	Cache sharing: Enables sharing the cache across different builds or build machines.
	Faster builds: Can significantly accelerate builds, especially for complex builds with many layers or frequent changes within specific parts of the codebase.
	Limitations:
	Manual setup: Requires creating and managing the cache directory.
	Increased complexity: Adds an extra step to the build process.
	Here's an analogy:

	Imagine building a house:
	Default layered caching: Each floor represents a layer. If you build a new house with the same floor plan, the foundation and existing floors (unchanged layers) can be reused, saving time (faster builds).
	-c option: You store pre-built floor plans (cached layers) in a separate location. When building a new house, you can check if the desired floor plan already exists in the cache and use it directly, further accelerating the construction process.

Choosing the Right Approach:

	For most basic Dockerfile usage, the default layered caching is sufficient. It offers a good balance of simplicity and efficiency.
	Consider using the -c option if:
	You need more control over the cache location and contents.
	You're working with complex builds with frequent changes in specific parts of the codebase.
	You're managing builds across multiple machines and want to share the cache.
---------------------------------------------------------------------------------------------------------------------------	
		Various strategies and comparisons
---------------------------------------------------------------------------------------------------------------------------	
	
	




Option				Layer Caching (built-in)	
	Description			Docker automatically caches layers based on the instructions used to create them.	- 
	Advantages			Improves build efficiency by reusing cached layers for subsequent builds.	- 
	Disadvantages		Limited control over specific files or layers to cache.	- 
	When to Use			Default option for most builds as it offers significant benefits with minimal effort.

Option				Build Caches (using docker build -c)	
	Description			Stores intermediate build stages for faster subsequent builds of the same image.	- 
	Advantages			Faster builds, especially for complex builds or frequent updates.	- 
	Disadvantages		Increased storage usage for cached layers. Requires manual management or automation.	- 
	When to Use			Consider using: - For complex builds with many steps. - When frequent updates involve changes only in specific parts of the codebase.

Option				Content Delivery Networks (CDNs)	
	Description			Stores cached copies of images geographically distributed across servers.	- 
	Advantages			Improves image delivery speed and reduces load on application servers. - Reduces latency for users based on their location.	- 
	Disadvantages		Additional cost associated with CDN service. May require integration with your deployment pipeline.	- 
	When to Use			Use for: - Static content like images, fonts, and scripts with high access frequency. - When reducing latency for geographically distributed users is critical.

Option				Image Pruning (using docker image prune)	
	Description			Removes unused image layers and containers.	- 
	Advantages			Reclaims disk space by eliminating unnecessary data.	- 
	Disadvantages		Requires manual execution or automated tasks. May remove cached layers if not used recently.	- 
	When to Use			Use: - To manage storage usage in environments with frequent image builds or experimentation. - As part of a regular cleanup routine for your Docker environment.

Option				Build Cache Management Tools	
	Description			Dedicated tools for managing build cache across multiple build machines.	- 
	Advantages			Centralized cache management for large-scale deployments. - Versioning and invalidation for cache control. - 
	Disadvantages		Advanced analytics and insights into cache usage.	- Additional cost and complexity compared to built-in caching options.	- 
	When to Use			Consider for: - Large-scale deployments with multiple build machines. - Scenarios requiring advanced control over caching and detailed analytics.	
		
	
---------------------------------------------------------------------------------------------------------------------------		

	3. Efficient Ways to Write Dockers
---------------------------------------------------------------------------------------------------------------------------	
	
	

	Efficient Ways to Write Dockerfiles:
	Here are some key practices to write efficient and well-structured Dockerfiles:

	1. Utilize Multi-stage Builds:

		Benefit: Reduce image size and improve security by separating build and runtime environments.
		Implementation:
		Create multiple stages in your Dockerfile. Build the application in one stage and copy only necessary files to the final, minimal image.

	2. Leverage Layer Caching:

		Benefit: Improve build speed by reusing cached layers during subsequent builds.
		Implementation:
		Minimize the number of RUN instructions and combine commands whenever possible to reduce the number of layers.
		Use caching-friendly base images that are frequently updated and have a high hit rate in public registries (e.g., official Docker images).
	3. Implement .dockerignore:

		Benefit: Exclude unnecessary files from being included in your image, reducing size.
		Implementation:
		Create a .dockerignore file in your project directory.
		Specify file or directory patterns to be excluded (e.g., .env, build artifacts, documentation).
		Example: Refer to the previous example of a .dockerignore file.
	4. Utilize Environment Variables:

		Benefit: Keep configuration details separate from the image, improving maintainability and security.
		Implementation:
		Define environment variables using the ENV instruction or pass them during container creation.
		Access them within your application using environment variable access mechanisms appropriate for your programming language.
	5. Choose Appropriate Base Images:

		Benefit: Utilize lean and well-maintained base images to reduce image size.
		Implementation:
		Select base images that contain only the necessary components for your application.
		Consider official base images from Docker Hub or reputable sources.
	6. Prioritize Healthchecks:

		Benefit: Improve the reliability and self-monitoring capabilities of your container.
		Implementation:
		Define a HEALTHCHECK instruction in your Dockerfile to specify how to determine if your container is healthy.
		Customize the check based on your application's specific health requirements.
		
		Example: https://www.naiyerasif.com/post/2021/03/01/java-based-health-check-for-docker/
	
	7. Maintain Readability and Documentation:

		Benefit: Ensure your Dockerfile is understandable and well-documented for others.
		Implementation:
		Use clear and concise instructions.
		Add comments to explain complex steps or reasoning behind choices.
		Consider documentation tools or comments to provide additional details about your image and its usage.
	8. Automate Builds and Deployments:

		Benefit: Improve efficiency and consistency by automating builds and deployments.
		Implementation:
		Utilize tools like CI/CD pipelines to automate builds and deployments based on code changes or triggers.
		Integrate container registries and container orchestration tools for managing your image lifecycle and deployments.	
	
---------------------------------------------------------------------------------------------------------------------------	
	◦ Tips for Reducing Image Size
---------------------------------------------------------------------------------------------------------------------------	
	
	
	
Reducing Docker Image Size: Strategies and Best Practices:
Building lean and efficient Docker images is crucial for optimal performance and deployment efficiency. Here are some key strategies to reduce image size:

1. Utilize Multi-stage Builds:

	Benefit: This is the most impactful approach for minimizing image size.
	Method: Separate the build process from the final runtime environment. Create stages:
	Stage 1 (Build): Install dependencies and build your application.
	Stage 2 (Final): Copy only essential files and configurations from the build stage to a minimal base image.
	This eliminates unnecessary build tools and libraries from the final image, significantly reducing its size.
2. Leverage Layer Caching:

	Benefit: Docker automatically caches layers based on the instructions used to create them.
	Implementation:
	Minimize the number of RUN instructions and combine commands whenever possible to reduce the number of layers.
	Use caching-friendly base images that are frequently updated and have a high hit rate in public registries (e.g., official Docker images).
3. Employ a .dockerignore file:

	Benefit: Exclude unnecessary files and directories from the image.
	Implementation:
	Create a .dockerignore file in your project directory.
	Specify patterns to exclude (e.g., build artifacts, documentation, development environment-specific files).
4. Choose Appropriate Base Images:

	Benefit: Start with a minimal base image containing only essential components.
	Implementation:
	Explore official base images from Docker Hub or reputable sources.
	Consider alternative base images with smaller footprints if official images are too large for your needs.
	Use :alpine variants of base images whenever possible, as they are generally smaller than their :debian counterparts.
5. Optimize Application Code:

	Benefit: Reducing code size also reduces the image size.
	Implementation:
	Implement code optimizations and remove unused code sections.
	Consider minifying and bundling your application code for smaller footprint.
6. Utilize Smaller Package Managers:

	Benefit: Some package managers have smaller footprints than others.
	Implementation:
	When applicable, consider using apk instead of apt in the build stage for smaller package management overhead in the final image.
7. Remove Unnecessary Dependencies:

	Benefit: Only include libraries and dependencies strictly required for your application's functionality.
	Implementation:
	Carefully review your dependencies and remove any unused or unnecessary ones during the build process.
8. Utilize Smaller Alternatives:

	Benefit: If available, consider smaller alternatives for specific libraries or tools.
	Implementation:
	Research and explore alternative libraries or tools that offer similar functionality with a smaller footprint.
9. Employ Multi-arch Builds (Optional):

	Benefit: Create a single image that can run on multiple architectures, potentially reducing the number of images you need to manage.
	Implementation:
	Utilize tools like buildx or native multi-arch support in Docker to build a single image that targets multiple architectures (e.g., amd64, arm64).
10. Consider Image Compression Tools (Advanced):

	Benefit: Tools like squashfs can further compress the image layers.
	Implementation:
	Use these tools with caution and be aware of potential trade-offs in image size reduction versus decompression overhead at runtime.
Remember:

Balance image size with functionality: While a smaller image is desirable, ensure you don't compromise essential functionalities by removing necessary components.
Test thoroughly: After making changes to your Dockerfile, always thoroughly test your image to ensure it functions correctly and meets your requirements.
Continuously evaluate: Regularly review and optimize your Dockerfile based on the specific needs of your application and development environment.
	
---------------------------------------------------------------------------------------------------------------------------	
		Overview of various strategies.
---------------------------------------------------------------------------------------------------------------------------	
	covered above.
---------------------------------------------------------------------------------------------------------------------------		
	◦ Techniques for Faster Builds
---------------------------------------------------------------------------------------------------------------------------	
	
comprehensive list of techniques you can employ to achieve faster Docker builds, categorized by their area of focus:

Optimizing the Dockerfile:

Multi-stage builds: Separate the build and runtime environments, minimizing the final image size and improving layer caching efficiency.
Layer caching: Leverage Docker's built-in layer caching to reuse previously built layers across subsequent builds with identical steps, saving significant time.
Minimize RUN instructions: Combine multiple commands into a single RUN instruction whenever possible to reduce the number of layers created.
Use caching-friendly base images: Choose base images that are frequently updated and have a high hit rate in public registries to maximize layer reuse.
Utilize .dockerignore file: Exclude unnecessary files and directories from the image, such as build artifacts, documentation, and temporary files, keeping the image lean.
Optimizing Build Resources:

Hardware upgrades: Consider upgrading your build machine's CPU, RAM, and storage for faster processing, increased caching capacity, and improved build speed.
Optimize resource allocation: Allocate sufficient CPU cores and RAM to the build process, ensuring it has the necessary resources for efficient execution.
Utilize a build cache: Docker allows using a build cache with the -c flag to store intermediate build stages, further accelerating subsequent builds with similar modifications.
Build Caching and Distribution:

Centralized build cache: For complex builds or large-scale deployments, consider implementing a centralized build cache management tool for efficient caching across multiple build machines.
Content Delivery Networks (CDNs): Utilize CDNs to store and deliver cached image layers geographically, reducing download times for geographically distant builds.
Build promotion strategies: Implement automated build promotion strategies to limit full builds to specific stages and only rebuild affected portions when necessary.
Additional Techniques:

Parallelization: Explore tools like Docker Compose or BuildKit that offer limited parallelization capabilities for specific build steps, potentially improving build speed for certain scenarios.
Optimize application code: While not directly impacting Docker build times, optimizing your application code can indirectly reduce the size of the final image, leading to faster downloads and potentially improving overall performance.
Choosing the Right Approach:

The optimal combination of techniques depends on your specific needs, project complexity, and available resources. Consider factors like:

Build complexity: Simple builds might benefit from basic layer caching, while complex builds might require a multi-pronged approach.
Build frequency: Frequent builds justify investing in build cache optimization and automation strategies.
Image size and usage: Utilize CDNs for frequently accessed images, and consider image size optimization techniques.
Deployment infrastructure: Centralized build cache management becomes more relevant for large-scale deployments.	
	
---------------------------------------------------------------------------------------------------------------------------	
		Overview of various strategies.
---------------------------------------------------------------------------------------------------------------------------	
	covered above.
---------------------------------------------------------------------------------------------------------------------------		
	◦ Strategies for Easy Maintenance and Upgrades
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		Overview of various strategies.
	---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
	◦ Utilizing Multi-Stage Builds
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		Hands on:
---------------------------------------------------------------------------------------------------------------------------	
	
	
	
---------------------------------------------------------------------------------------------------------------------------


	4. Building and Running Dockers
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
	◦ Docker Build Process
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		deep dive into build process.
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
	◦ Running Containers with docker run
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		Deep dive into different options.
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
		Best practices
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
	◦ Container Lifecycle
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		Deep dive into Container lifecycle
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
	◦ Docker CLI Basics
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------

	5. Using CPUs with Docker - Customizations
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		◦ Specifying CPU Shares and Limits
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
			How do you specify the limits?
	---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
			How does it internally work?
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------			
			What are the best practices
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------			
		◦ Using CPU Affinity
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
			Check Host CPU Configuration:
	---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
			Start a Docker Container with CPU Affinity
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------			
			Advantages and disadvantages of CPU Affinity
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------			
		◦ Resource Management with docker-compose
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
			docker-compose introduction
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------			
			Define Resource Reservation in docker-compose
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------			
				Best practices
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------
	6. Using GPUs with Docker - Customizations
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
	◦ GPU Support in Docker
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		Setup and work with GPU in containers
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
	◦ Running GPU-Enabled Containers
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
	◦ Leveraging GPUs for Enterprise usage.
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		Options and best practices
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------
	7. Using Dockers with VSCode Extension
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		◦ Introduction to Visual Studio Code and Docker
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
			Install Visual Studio Code pluggin for Docker
	---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
			Working from VS Code
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------			
		◦ Setting Up Docker Extension in VSCode
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
		◦ Building, Running, and Debugging Containers from VSCode
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
			Best practices
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------
8. Docker Registry
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------
	◦ Overview of Docker Registries
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
		Various Docker registry options
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------		
	◦ Docker Hub and Other Registry Options
	
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
	◦ Pushing and Pulling Images
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	
	◦ Private Docker Registries
---------------------------------------------------------------------------------------------------------------------------	
	
---------------------------------------------------------------------------------------------------------------------------	


Good reference dockerfile: 
	https://github.com/nickjj/docker-flask-example/blob/main/Dockerfile
	https://github.com/sytone/obsidian-remote/blob/main/Dockerfile
	
	https://github.com/nodejs/docker-node/blob/main/Dockerfile-alpine.template
	https://github.com/nodejs/docker-node/blob/main/Dockerfile-debian.template
	https://github.com/nodejs/docker-node/blob/main/Dockerfile-slim.template
	
	
	Multistage Node example - section 8.1 ownwards 
		https://github.com/goldbergyoni/nodebestpractices
		
	docker-compose reference: 
		https://github.com/laradock/laradock/blob/master/docker-compose.yml	
		
	Docker reference: 
		https://github.com/veggiemonk/awesome-docker
	
	Non-root user 
		https://dev.to/izackv/running-a-docker-container-with-a-custom-non-root-user-syncing-host-and-container-permissions-26mb